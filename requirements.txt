
# Core dependencies
einops>=0.8.0
numpy==1.26.4
pillow==11.3.0
diffusers>=0.32.0
safetensors==0.4.5
tokenizers>=0.21.0
transformers[accelerate,tiktoken]>=4.56.0
huggingface_hub[cli]

# PyTorch with CUDA 12.8 support (install separately)
# torch==2.7.1
# torchvision==0.22.1  
# torchaudio==2.7.1
# Install with: pip install torch==2.7.1 torchvision==0.22.1 torchaudio==2.7.1 --index-url https://download.pytorch.org/whl/cu128

# Performance optimizations (recommended for up to 3x faster inference)
# flash-attn==2.8.3 --no-build-isolation
# flashinfer-python

# Interactive demo
gradio>=4.21.0



